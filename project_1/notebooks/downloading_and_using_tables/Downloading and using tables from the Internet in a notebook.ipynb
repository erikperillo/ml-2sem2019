{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and using tables from the Internet in a notebook\n",
    "\n",
    "We can use files present in the host running a notebook normally.\n",
    "This notebook exemplifies how we can load the data used in project 1, automatically downloading the file if it's still not present in the host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the relevant modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS files manipulation\n",
    "import os\n",
    "# web interaction\n",
    "import requests\n",
    "# files unzipping\n",
    "import gzip\n",
    "# csv files/tables manipulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the web and local paths of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web location of the dataset table\n",
    "DATASET_URL = ('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "    '00492/Metro_Interstate_Traffic_Volume.csv.gz')\n",
    "# location of the local dataset table\n",
    "DATASET_LOCAL_PATH = 'data/dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following methods to download, unzip and open the dataset .csv table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, dst_path):\n",
    "    '''Downloads a file from given url to destination path.'''\n",
    "    resp = requests.get(url)\n",
    "    with open(dst_path, 'wb') as f:\n",
    "        f.write(resp.content)\n",
    "        \n",
    "        \n",
    "def gunzip(path, dst_path):\n",
    "    '''Unzips a gzip file from given path do destination path.'''\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        with open(dst_path, 'wb') as dst_f:\n",
    "            dst_f.write(f.read())\n",
    "\n",
    "\n",
    "def download_and_unzip_dataset():\n",
    "    '''Downloads and unzips dataset to be used in project.'''\n",
    "    # making sure the directory that will hold our file exists\n",
    "    os.makedirs(os.path.dirname(DATASET_LOCAL_PATH), exist_ok=True)\n",
    "    # downloading file from internet\n",
    "    download(DATASET_URL, f'{DATASET_LOCAL_PATH}.gz')\n",
    "    # unzipping file to final destination\n",
    "    gunzip(f'{DATASET_LOCAL_PATH}.gz', DATASET_LOCAL_PATH)\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    '''Gets the dataset to be used in project as a pandas table.'''\n",
    "    # if the file still does not exist locally, get it from the internet\n",
    "    if not os.path.isfile(DATASET_LOCAL_PATH):\n",
    "        print('downloading dataset from '\n",
    "            f'{DATASET_URL} to {DATASET_LOCAL_PATH}...', end=' ', flush=True)\n",
    "        download_and_unzip_dataset()\n",
    "        print('done.\\n')\n",
    "\n",
    "    # load the csv table\n",
    "    df = pd.read_csv(DATASET_LOCAL_PATH)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading dataset from https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz to data/dataset.csv... done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can finally use our dataset as we wish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first rows of dataset:\n",
      "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
      "0    None  288.28      0.0      0.0          40       Clouds   \n",
      "1    None  289.36      0.0      0.0          75       Clouds   \n",
      "2    None  289.58      0.0      0.0          90       Clouds   \n",
      "3    None  290.13      0.0      0.0          90       Clouds   \n",
      "4    None  291.14      0.0      0.0          75       Clouds   \n",
      "\n",
      "  weather_description            date_time  traffic_volume  \n",
      "0    scattered clouds  2012-10-02 09:00:00            5545  \n",
      "1       broken clouds  2012-10-02 10:00:00            4516  \n",
      "2     overcast clouds  2012-10-02 11:00:00            4767  \n",
      "3     overcast clouds  2012-10-02 12:00:00            5026  \n",
      "4       broken clouds  2012-10-02 13:00:00            4918  \n",
      "\n",
      "the dataset contains 48204 rows and 9 columns.\n",
      "dataset columns are: holiday, temp, rain_1h, snow_1h, clouds_all, weather_main, weather_description, date_time, traffic_volume\n"
     ]
    }
   ],
   "source": [
    "print('first rows of dataset:')\n",
    "print(df.head())\n",
    "print()\n",
    "\n",
    "n_rows, n_cols = df.shape[:2]\n",
    "print(f'the dataset contains {n_rows} rows and {n_cols} columns.')\n",
    "print(f'dataset columns are: {\", \".join(df.columns)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
